\documentclass[a4paper]{article}
\usepackage{a4wide}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{array}
\usepackage{hyperref}
\usepackage{placeins}
\usepackage{amsmath}

% bibliography style
\usepackage[sectionbib,round]{natbib}
\bibliographystyle{mybst}
\setcounter{secnumdepth}{3}

\begin{document}

\title{Appendix S2 - Instructions for reproducing the simulation results}
\date\today
\maketitle
\section{Introduction}
This document is designed to help you replicate the analysis presented in Isaac et al., 2014. If you are only interested in replicating the analysis as presented in our paper then sections 2 and 3 should satisfy your needs, however if you are interested in learning more about the code we used to produce our results, sections 4 onward go into a little more detail.

\section{Setup}
Getting setup is easy if you are already a regular R user but a bit more complicated if you are not. Not to worry, we are here to hold your hand.

\begin{enumerate}
  \item You will need to install two pieces of software to run the full analysis. The first is R, you will need to download this from \url{http://cran.r-project.org/}. 
  \item The second is JAGS, which is used to run occupancy models. You can download this from \url{http://sourceforge.net/projects/mcmc-jags/files/JAGS/3.x/}
  \item To download all the code for our analyses, and to have a go yourself use this link: \url{https://github.com/BiologicalRecordsCentre/RangeChangeSims/archive/master.zip}. This will download a .zip file (10.9MB) containing everything you need. 
  \item Extract the .zip file to your machine. Now we are ready to go!
  \item IMPORTANT: Our code relies on a number of packages and as they change over time our code may start to experience issues. Once such instance has already occurred and the latest version of reshape2 does not function correctly with our code. To rectify this, if you have a version of reshape2 greater than 1.2.2, we have included a version of reshape2 in our zip that you can install and will work. For our full sessionInfo see the last section of this tutorial. 
\end{enumerate}

\section{Replicating the paper}

To replicate the analysis as in Isaac et al. 2014, find the script 'Run\_full\_analysis.r' from the .zip file and run it in R (make sure your working directory is set to the folder this script is in). The script will install required packages, check that JAGS is working, run the analyses (you can specify the number of runs to do) and plot all figures and tables from the results. The results will be saved in the working directory. However, this is a computationally intensive task and to replicate the full 1000 runs presented in the paper and Appendix S1 on a regular desktop PC will take approximately 170 days! We addressed this problem by using a computer cluster, achieving a run time of under a week. The only function that cannot be run in parallel on a cluster is frescalo as this uses a Windows complied executable.

\section{Analysis: Step by Step}

Here we demonstrate a few of the functions we have written that will give you a deeper understanding of our methods and provide the potential to test out your own methods using our framework.

To access all the functions we simply source in the function script from the R console by typing the following:

<<warning=FALSE>>=
source('Sim_functions.r')
@

You will need to ensure that 'Sim\_functions.r' reflects the file path from your current working directory to the functions script. You can change your working directory using the \texttt{setwd} function

We will look at a number of functions, each builds on the previous function and is often a wrapper around the simpler functions. 

\begin{description}
  \item[\texttt{create\_data}] \hfill \\
  Randomly generates 'true' data. This is a binary table indicating the presence/absence of each species at each site.
  \item[\texttt{recording\_visit}] \hfill \\
  Send out our virtual recorders on a visit and return what they find
  \item[\texttt{recording\_cycle}] \hfill \\
  Send out our virtual recorders on a year's worth of sampling to multiple sites
  \item[\texttt{generate\_records}] \hfill \\
  Undertake virtual recording across multiple years in our simulated study
  \item[\texttt{generate\_all\_scenarios}] \hfill \\
  Undertake virtual recording, producing results for each recording scenario
  \item[\texttt{run\_all\_methods}] \hfill \\
  Take a dataset of records and apply to this a suite of modelling methods
  \item[\texttt{iterate\_all\_scenarios}] \hfill \\
  Combine the previous two functions and allow multiple runs, each run using new data generated by \texttt{generate\_all\_scenarios} 
  \item[\texttt{get\_all\_stats}] \hfill \\
  Produce summary information from the results of \texttt{iterate\_all\_scenarios}
\end{description}

\subsection{Generating simulated data}

Simulated data can be created using the 'true\_data' function. This function generates 'true' data telling us whether each species is present or absent from each location which we can later use to build our observation data (see section 'Species occurrence matrices' in the methods section of the manuscript).

<<>>=
# Create our 'true' data
true_data <- create_data(nSites = 1000,
                         nSpecies = 25,
                         pFocal = list(Occ = 0.5, DetP = 0.5))

head(true_data)

# true_data has some useful attributes
str(attributes(true_data))
@

\texttt{nSites} specifies the number of sites we want, \texttt{nSpecies} specifies the number of species, and \texttt{pFocal} specifies the occurrence probability of the species (\texttt{Occ}), and the probability of detection of the focal species on a given visit (\texttt{DetP}). There are some attributes assigned to \texttt{true\_data} that can be quite informative. The two elements of \texttt{dimnames} give the names of sites and species respectively, \texttt{richness} gives the species richness of each site as listed in \texttt{dimnames}, and \texttt{p\_detect} gives the probability of detection for each species as listed in \texttt{dimnames}.

\subsection{Nested functions: Visits within years within year ranges}

The following examples detail the generation of the control scenario data described in the 'Control scenario' section in the methods section of the manuscript. At the lowest level of our models is the concept of a visit. Here we take the 'true' data that we just generated and send out our virtual recorders to a site. The function takes the true occurrence of the species at the site as well as the sampling intensity for each species and returns what was recorded by our virtual recorders.

<<>>=
# Get the true data for one site
site1 <- true_data['site1',]

# Send out our virtual recorders
observations <- recording_visit(spp_vector = site1, p_obs = attr(true_data, 'p_detect')) 

# View the species actually present
names(site1[site1==1])

# View the species recorded by our observers
names(observations[observations==1])
@

\texttt{recording\_visit} is wrapped up in the function \texttt{recording\_cycle} which allows us to undertake a years sampling in one go. The resulting data.frame gives us a row for each observation with columns for species, visit and site.

<<>>=
# Undertake a year's sampling setting the recording intensity to 7% (medium)
year1 <- recording_cycle(pSVS = 0.07, true_data = true_data)

# Preview our results
head(year1)
@

In \texttt{recording\_cycle}, \texttt{pSVS} specifies the overall recording intensity as described in the 'control scenario' section of the methods section of the manuscript. Recording\_cycle has three optional arguments: \texttt{max\_vis} defines the maximum number of visits that a site can receive in any year (fixed at 10); \texttt{stochastic} defines whether the number of visits is fixed each year (\texttt{stochastic=FALSE}) or whether it varies from year to year (\texttt{stochastic=TRUE}), as in the simulations; \texttt{VisRichSites} determines how visits are apportioned among sites. There are two components: a \texttt{sel} component determines whether sites with higher species richness are more likely to be selected for a visit; the \texttt{num} component determines whether the number of visits received (once selected) is determined by species richness. The default is that both components are set to be \texttt{FALSE}, but in our simulations we set \texttt{sel=FALSE} and \texttt{num=TRUE}.

We further wrap \texttt{recording\_cycle} within the function \texttt{generate\_records} which allows us to create our baseline unbiased records for all years of the study. In this example we implement an unrealistically dramatic decline in most of our species, this is just for demonstration and does not reflect any of the scenarios we used in the manuscript.

<<tidy.opts=list(width.cutoff=60)>>=
# Set up our parameters
nYrs = 10 # The number of years we wish to run
which.decline = 1:20 # Specify which species we wish to be in decline
decline = rep(0.7, 20) # The rate of decline of each speces (here all 70%)
pSVS = 0.07 # Set our recording effort to 7% (medium)
mv=10 # Set the maximum number of visits to a site in a year to 10

# Generate our records
years10 <- generate_records(nYrs = nYrs, true_data = true_data, 
                            decline = decline, pSVS = pSVS, 
                            mv = mv, which.decline = which.decline)

# Preview our results
head(years10)

# Look for our simulated decline
plot(table(years10$Year), xlab = 'Year',
     ylab = 'Number of species records/year', type = 'l')
@

The data is returned in the same format as in \texttt{recording\_cycle} but now contains data across all the years of our virtual study. We can see from the plot that the 70\% decline we have simulated in the majority of species has resulted in a reduction in the number of records per year as a result of species going extinct from sites over the duration of the study.

\subsection{Applying sampling scenarios}

To create our simulated recording data we use the true data and a number of sampling protocols described in our paper. Each scenario uses the \texttt{generate\_records} function (described above) to generate data and then sub\-samples this data according to the specifics of the scenario (see 'Biased recording scenarios' in the methods section of the manuscript).

For ease of coding scenarios were grouped using a letter which was used in the \texttt{Scenarios} argument of \texttt{generate\_all\_scenarios}. For historic reasons the scenarios names are different in our code and the manuscript. We present these different naming conventions in Table \ref{table:scenarios}

\begin{table}
\caption{Scenario codes}
\centering
\begin{tabular}{ c | c | c }
\hline
\textbf{Grouping letter} & \textbf{Name in code} & \textbf{Name in manuscript} \\ \hline
A & A\_EvenRcrdng & Control \\ 
B & B2\_IncrnVisit & MoreVisits \\ 
B & B3f\_IncrnVBiasFc & MoreVisits+Bias \\ 
C & C1\_pShortLEven & NA \\ 
C & C2\_pShortLIncr & LessEffortPerVisit \\ 
D & D2\_SelectvIncr & MoreDetectable \\ 
F & F\_NfDecline & NonFocalDeclines \\     
\end{tabular}
\label{table:scenarios}
\end{table}
\FloatBarrier

The task of generating the true data and from this generating records for each simulated recording scenario is handle by \texttt{generate\_all\_scenarios}.

<<tidy.opts=list(width.cutoff=60)>>=
# Produce the records for each recording scenario
recs <- generate_all_scenarios(nSites = 1000,
                              nSpecies = 25,
                              pFocal=list(Occ = 0.5, DetP = 0.5),
                              nYrs = 10,
                              pSVS = 0.07,
                              mv = 10,
                              Scenarios = 'BCDF',
                              p_short = list(init = 0.6, final = 0.9),
                              pDetMod = 0.2,
                              decline = 0)

# The output is a list of data.frames, one for each Scenario
length(recs)

# A preview of the results from the MoreVisits+Bias scenario
head(recs$B3f_IncrnVBiasF, 10)
@

We have covered some of these parameters in previous sections (\texttt{nSites}, \texttt{nSpecies}, \texttt{pFocal}, \texttt{nYrs}, \texttt{pSVS}, \texttt{mv}), here is a brief description of those that are new. \texttt{Scenarios} is a string that specifies the scenarios that are to be generated as given in the table above by grouping letter (scenario A is run by default). \texttt{p\_short} is used for both 'C' scenarios and gives the proportion of lists that should be 'short' on the first (\texttt{init}) and last (\texttt{final}) year of the simulation. \texttt{pDetMod} defines the proportion of lists where the focal species should be 'unrecorded' and is used to simulate reduced detectability in scenario 'D'. \texttt{decline} gives the proportional decline of the focal species across the duration of the study period (here 10 years). We set this to 0.3 when testing the power of statistical methods.

\texttt{generate\_all\_scenarios} returns a list of data.frames. Each data.frame is the result of a recording scenario, giving a list of observations. This details the species recorded, the year, visit and site on which it was recorded. Note that multiple visits can be made to a site in a given year.

BUGS code for different Occupancy-Detection models are each contained in a separate file. The code for OccDetSimple is in a file called “Occ\_Simple.bugs”. The code for OD+SF+LL+Site is in a file called “Occ\_LL\_Site.bugs”. There are also BUGS code files to run other combinations listed in table \ref{table:models}.

\subsection{Running analyses}

Once we have generated our records we can them test for trends using the various methods explored in the paper. When undertaking the analyses we explored a range of methods but have chosen not to describe all of them in the manuscript. Table \ref{table:models} gives the codes used for each of the methods discussed in the manuscript and some extras. The details of the methods included in the manuscript can be found in Appendix S2.

\begin{table}
\caption{Model codes}
\centering
\begin{tabular}{ l | l | l }
\hline
\textbf{Code} & \textbf{Name} & Included in manuscript?\\ \hline
nSites & Naive & Yes \\ 
Telfer & Telfer & Yes \\ 
Frescalo1tp & Frescalo\_Y & Yes \\
Frescalo2tp & Frescalo\_P & Yes \\
VRsimple & ReportingRate & Yes \\
LLsimple & RR+LL & Yes\\
RR\_SS & RR+SF & Yes\\ 
MMbin0 & RR+Site & Yes\\ 
LLmm & RR+LL+Site & No\\ 
mmSS & RR+SF+Site & No\\ 
LLSS & RR+SF+LL & No\\ 
LLmmSS & RR+SF+LL+Site & Yes\\ 
Occ+Simple & OccDetSimple & Yes\\ 
Occ+LL+Site & Occ+LL+Site & No\\ 
Occ+SS+Site & Occ+SF+Site & No\\ 
Occ+SS+LL & OD+SF+LL & No\\ 
RR\_SS3 & RR+SF3 & No\\ 
LLmmSS3 & RR+LL+SF3+Site & No\\ 
Occ+SS3+Site & Occ+SF3+Site & No\\ 
Occ+SS3+LL & Occ+LL+SF3 & No\\ 
Occ+Full & OD+SF+LL+Site & Yes\\ 
MMbin2sp & WSS\_2 & No\\ 
MMbin4sp & WSS\_4 & No\\ 
Maes & RDC & No\\ 
\end{tabular}
\label{table:models}
\end{table}

Here we use the function \texttt{run\_all\_methods} to run a range of analytical methods on one of the recording scenarios we have simulated. While this function runs most of the methods by default a couple of methods require us to provide extra details.

<<tidy.opts=list(width.cutoff=60), warning=FALSE>>=
# Lets analyse the control scenario
scenario1 <- recs$A_EvenRcrdng

# Specify the occupancy models we want to run
# These model specify OccDetSimple and OD+SF+LL+Site respectivly
Occ <- c('Simple', 'Full')

# Run the analyses
results <- run_all_methods(records = scenario1,
                           nyr = 2,
                           OccMods = Occ,
                           Frescalo = c(1,2))
@

\texttt{nyr} dictates that only sites which received visits in at least \texttt{nyr} of the ten years in the simulation are included in site-filtered models (+SF). \texttt{OccMods} names the occupancy models that we would like to use. \texttt{Frescalo} specifies the versions of frescalo we want to run, 1 meaning Frescalo\_Y and 2 meaning Frescalo\_P.

<<>>=
# Preview the results
head(results)

# List the names of all the parameters returned
names(results)
@

The returned object 'results' is a vector of attributes. There are numerous parameters returned and Table \ref{table:results} gives details for those of note.

\begin{table}
\caption{run\_all\_methods output parameters per dataset, or mean across datasets when using iterate\_all\_scenarios}
\centering
\begin{tabular}{ l | p{10cm} }
\hline
\textbf{Parameter name} & \textbf{Explanation} \\ \hline
\text{*}\_trend & Specifies the trend estimated for the focal species \\ 
\text{*}\_p & Indicates the significance of the estimated trend \\ 
\text{*}\_pCombosUsed & Specifies, for models that used only data from 'well sampled sites', the proportion of visits that were used in the model \\ 
\text{*}\_Rhat & A test of convergence in MCMC chains in occupancy models, values around 1 indicate convergence \\ 
\text{*}\_t1 & Time period 1: years 1-5 \\
\text{*}\_t2 & Time period 2: years 6-10 \\
Fr\_Phi & In Frescalo, the target frequency of frequency-weighted mean frequency (see Hill, 2012)\\ 
Fr\_MedianAlpha & The median value of alpha, an estimate of recording intensity, across all sites (see Hill, 2012) \\
Recs\_pBnchmk & The proportion of records that are of 'benchmark' species (see Hill, 2012) \\
Recs\_qFocal & The quantile of the focal species when ranked against all other species by total number of records \\
Recs\_tot\_visits & The total number of visits in the simulation \\
Recs\_Sp\_Yr & Average number of records per species year \\
Recs\_total & The total number of records in the simulation \\
Recs\_focal & The the number of records of the focal species in the simulation \\
VisPerYr & The average number of visits per year \\
focal & The proportion of visits on which the focal species was recorded \\
nonfocal & The proportion for visits on which a species was recorded, averaged across all non-focal species \\
meanL & The mean list length across visits \\
p\_shortLists & The proportion of visits that returned short lists (3 species or less) \\
MeanSitesVisited & The mean number of sites visited per year \\
PrSitesMultiVisit & The proportion of sites that once visited once receive another visit in the same year \\
\end{tabular}
\label{table:results}
\end{table}
\FloatBarrier

When running our full analysis we wanted to run numerous simulations for testing. We therefore wanted to run \texttt{generate\_all\_scenarios} many times and use \texttt{run\_all\_methods} on each scenario of each run. We wrote a function called \texttt{iterate\_all\_scenarios} that combines the former methods and allows us to do multiple runs. In the example below I turn off occupancy models (\texttt{Occ = NULL}) and frescalo (\texttt{Frescalo = FALSE}), and consider fewer scenarios to reduce the amount of time it takes to run.

<<tidy.opts=list(width.cutoff=60), warning=FALSE>>=
# Run multiple iterations, here set to 2
output <- iterate_all_scenarios(nreps = 2,
                                nSpecies = 25,
                                nSites = 500,
                                nYrs = 10, 
                                pSVS = 0.07,
                                Scenarios = 'B',
                                pFocal = list(Occ = 0.5, DetP = 0.5),
                                decline = 0,
                                Frescalo = FALSE,
                                Occ = NULL,
                                nyr = 2,
                                writePath = 'Output')

# Examine dimensions
dim(output)
dimnames(output)
@

\texttt{iterate\_all\_scenarios} returns a three dimensional object. The first dimension gives the parameters as returned by \texttt{run\_all\_methods} and detailed in the table above. The second dimension represents each of the recording scenarios selected and the third represents each of the repeats as specified by \texttt{nreps}. This function also takes an argument \texttt{writePath} which is were the data generated will be saved.

\subsection{Error rates}

To examine changes in error rate and power as we have done in our manuscript we must expand on the code in the previous section. Here we analyse two levels of recording effort, and with the focal species both stable and in decline. The former allows us to test the effects of recording effort and the latter allows us to explore model validity and power. In addition we use the function \texttt{get\_all\_stats} to get meaningful results from the data generated.

<<tidy.opts=list(width.cutoff=60), warning=FALSE>>=
# Create a parameter to hold our results
SimOut <- NULL

# Loop through our parameter settings
for(decline in c(0, 0.3)){
  for(pSVS in c(0.05, 0.07, 0.1)){
    
    # Create an id which captures information about the run
    # V for Validation, P for power (depends if the focal species is in decline or not)
    ch <- ifelse(decline == 0, 'V', 'P')
    # Add to this details of the pSVS setting and the date
    id = paste(ch,'_',pSVS*100,'SVS_',format(Sys.Date(),'%y%m%d'), sep='')
    
    # Run multiple iterations 10 takes 1 minute
    output <- iterate_all_scenarios(nreps = 10,
                                    nSpecies = 25,
                                    nSites = 500,
                                    nYrs = 10, 
                                    pSVS = pSVS,
                                    Scenarios = 'B',
                                    pFocal = list(Occ = 0.5, DetP = 0.5),
                                    decline = decline,
                                    Frescalo = FALSE,
                                    Occ = NULL,
                                    nyr = 2,
                                    id = id,
                                    writePath = 'Output')
    
    # Create meaningful results from the data
    Out <- get_all_stats(output, save_to_txt = TRUE, writePath = 'Output')
    
    # Create attributes to capture the parameters used
    attr(Out, 'decline') <- decline
    attr(Out, 'pSVS') <- pSVS
    
    # Add these results to a list
    SimOut <- c(SimOut, list(Out))
  }
}
@

\texttt{get\_all\_stats} creates a series of summary statistics for each scenario, across repeats. During its run it prints to screen on the occasions when, for a declining focal species, the model suggests it is in fact increasing. At the top of our results, against the name of each method we have the proportion of repeats that gave a significant decline for the focal species:

<<tidy.opts=list(width.cutoff=60)>>=
# Lets look at one set of results
res <- SimOut[[1]]

# This set of results is for pSVS = 0.05, decline = 0
attr(res, 'pSVS')
attr(res, 'decline')

# The first rows give proportion of repeats that gave a significant decline for the focal species
# Each column represents a recording scenario
head(res)
@

For those parameters discussed in Table \ref{table:results} the figure in this summary table represents the average:

<<tidy.opts=list(width.cutoff=60)>>=
# Summariesd parameters are given.
# These include records parameters...
res[17:24,]

# ...and trend estimates
res[37:44,]
@

At the end of this table we have information on the number of valid repeats that were done:

<<tidy.opts=list(width.cutoff=60)>>=
# The number of repeats are given for each model
res[52:57,]
@

These summary statistics are the basis of the graphs presented in our manuscript

\section{Creating graphs}

In the manuscript we present a number of figures that summarize our results. These can be replicated using the function \texttt{Explore\_results}. This function takes two parameters: \texttt{writePath} and \texttt{readPath}. These specify the file path where you want data to be written to and the path where you are reading your data files in from. In this case we saved our results from the previous section to a folder called 'Output' so we will use that as our \texttt{readPath}. By setting \texttt{plot = TRUE} we can get the the figures to print to screen as well as being saved to file.

<<tidy.opts=list(width.cutoff=60)>>=
# Createmanuscript tables and figures from our results
Explore_results(readPath = 'Output',writePath = 'Results', plot = TRUE)
@

\section{References}

Hill, M.H. (2012) Local frequency as a key to interpreting species occurrence data when recording effort is not known. Methods in Ecology and Evolution, 3 (1), 195-205.

\section{Our sessionInfo}

Here is our sessionInfo. This is to aid people who encounter problems in the future that may be related to the packages we used at the time of writing this code.

<<>>=
# Print our sessionInfo
sessionInfo()
@

\end{document}